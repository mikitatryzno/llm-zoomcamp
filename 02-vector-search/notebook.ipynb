{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f23a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:29<00:00,  5.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embedding: (512,)\n",
      "Minimum value in the embedding: -0.11726373885183883\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_model = TextEmbedding(model_name=\"jinaai/jina-embeddings-v2-small-en\")\n",
    "\n",
    "# Embed the query\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "query_embedding = list(embedding_model.embed([query]))[0]\n",
    "\n",
    "# Check the shape of the embedding\n",
    "print(f\"Shape of embedding: {query_embedding.shape}\")  # Should be (512,)\n",
    "\n",
    "# Find the minimal value in the array\n",
    "min_value = query_embedding.min()\n",
    "print(f\"Minimum value in the embedding: {min_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf46ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query vector norm: 1.0\n",
      "Document vector norm: 1.0\n",
      "Cosine similarity: 0.9008528895674548\n"
     ]
    }
   ],
   "source": [
    "# Embed the document\n",
    "doc = 'Can I still join the course after the start date?'\n",
    "doc_embedding = list(embedding_model.embed([doc]))[0]\n",
    "\n",
    "# Compute cosine similarity (dot product of normalized vectors)\n",
    "import numpy as np\n",
    "cosine_similarity = query_embedding.dot(doc_embedding)\n",
    "\n",
    "# Verify that vectors are normalized\n",
    "print(f\"Query vector norm: {np.linalg.norm(query_embedding)}\")  # Should be close to 1.0\n",
    "print(f\"Document vector norm: {np.linalg.norm(doc_embedding)}\")  # Should be close to 1.0\n",
    "\n",
    "print(f\"Cosine similarity: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c81e86ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with highest similarity: 1\n",
      "Similarity score: 0.8182378150042889\n",
      "Document text: Yes, we will keep all the materials after the course finishes, so you can follow the course at your ...\n"
     ]
    }
   ],
   "source": [
    "documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first \\\"Office Hours\\\" live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon't forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]\n",
    "\n",
    "# Embed all document texts\n",
    "doc_texts = [doc['text'] for doc in documents]\n",
    "doc_embeddings = list(embedding_model.embed(doc_texts))\n",
    "\n",
    "# Create a matrix of document embeddings\n",
    "import numpy as np\n",
    "V = np.vstack(doc_embeddings)\n",
    "\n",
    "# Compute cosine similarities with the query\n",
    "similarities = V.dot(query_embedding)\n",
    "\n",
    "# Find the document with highest similarity\n",
    "highest_idx = np.argmax(similarities)\n",
    "highest_similarity = similarities[highest_idx]\n",
    "\n",
    "print(f\"Document with highest similarity: {highest_idx}\")\n",
    "print(f\"Similarity score: {highest_similarity}\")\n",
    "print(f\"Document text: {documents[highest_idx]['text'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d6c019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with highest similarity (full text): 0\n",
      "Similarity score: 0.8514543236908068\n",
      "Document question: Course - Can I still join the course after the start date?\n"
     ]
    }
   ],
   "source": [
    "# Create full_text by concatenating question and text\n",
    "full_texts = [doc['question'] + ' ' + doc['text'] for doc in documents]\n",
    "\n",
    "# Embed the full texts\n",
    "full_text_embeddings = list(embedding_model.embed(full_texts))\n",
    "\n",
    "# Create a matrix of full text embeddings\n",
    "V_full = np.vstack(full_text_embeddings)\n",
    "\n",
    "# Compute cosine similarities with the query\n",
    "similarities_full = V_full.dot(query_embedding)\n",
    "\n",
    "# Find the document with highest similarity\n",
    "highest_idx_full = np.argmax(similarities_full)\n",
    "highest_similarity_full = similarities_full[highest_idx_full]\n",
    "\n",
    "print(f\"Document with highest similarity (full text): {highest_idx_full}\")\n",
    "print(f\"Similarity score: {highest_similarity_full}\")\n",
    "print(f\"Document question: {documents[highest_idx_full]['question']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "525de528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "{'model': 'BAAI/bge-base-en', 'sources': {'hf': 'Qdrant/fast-bge-base-en', 'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en.tar.gz', '_deprecated_tar_struct': True}, 'model_file': 'model_optimized.onnx', 'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.', 'license': 'mit', 'size_in_GB': 0.42, 'additional_files': [], 'dim': 768, 'tasks': {}}\n",
      "{'model': 'BAAI/bge-base-en-v1.5', 'sources': {'hf': 'qdrant/bge-base-en-v1.5-onnx-q', 'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en-v1.5.tar.gz', '_deprecated_tar_struct': True}, 'model_file': 'model_optimized.onnx', 'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.', 'license': 'mit', 'size_in_GB': 0.21, 'additional_files': [], 'dim': 768, 'tasks': {}}\n",
      "{'model': 'BAAI/bge-large-en-v1.5', 'sources': {'hf': 'qdrant/bge-large-en-v1.5-onnx', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'model.onnx', 'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.', 'license': 'mit', 'size_in_GB': 1.2, 'additional_files': [], 'dim': 1024, 'tasks': {}}\n",
      "{'model': 'BAAI/bge-small-en', 'sources': {'hf': 'Qdrant/bge-small-en', 'url': 'https://storage.googleapis.com/qdrant-fastembed/BAAI-bge-small-en.tar.gz', '_deprecated_tar_struct': True}, 'model_file': 'model_optimized.onnx', 'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.', 'license': 'mit', 'size_in_GB': 0.13, 'additional_files': [], 'dim': 384, 'tasks': {}}\n",
      "{'model': 'BAAI/bge-small-en-v1.5', 'sources': {'hf': 'qdrant/bge-small-en-v1.5-onnx-q', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'model_optimized.onnx', 'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.', 'license': 'mit', 'size_in_GB': 0.067, 'additional_files': [], 'dim': 384, 'tasks': {}}\n",
      "{'model': 'BAAI/bge-small-zh-v1.5', 'sources': {'hf': 'Qdrant/bge-small-zh-v1.5', 'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-zh-v1.5.tar.gz', '_deprecated_tar_struct': True}, 'model_file': 'model_optimized.onnx', 'description': 'Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.', 'license': 'mit', 'size_in_GB': 0.09, 'additional_files': [], 'dim': 512, 'tasks': {}}\n",
      "{'model': 'mixedbread-ai/mxbai-embed-large-v1', 'sources': {'hf': 'mixedbread-ai/mxbai-embed-large-v1', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.', 'license': 'apache-2.0', 'size_in_GB': 0.64, 'additional_files': [], 'dim': 1024, 'tasks': {}}\n",
      "{'model': 'snowflake/snowflake-arctic-embed-xs', 'sources': {'hf': 'snowflake/snowflake-arctic-embed-xs', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.', 'license': 'apache-2.0', 'size_in_GB': 0.09, 'additional_files': [], 'dim': 384, 'tasks': {}}\n",
      "{'model': 'snowflake/snowflake-arctic-embed-s', 'sources': {'hf': 'snowflake/snowflake-arctic-embed-s', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.', 'license': 'apache-2.0', 'size_in_GB': 0.13, 'additional_files': [], 'dim': 384, 'tasks': {}}\n",
      "{'model': 'snowflake/snowflake-arctic-embed-m', 'sources': {'hf': 'Snowflake/snowflake-arctic-embed-m', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.', 'license': 'apache-2.0', 'size_in_GB': 0.43, 'additional_files': [], 'dim': 768, 'tasks': {}}\n",
      "{'model': 'snowflake/snowflake-arctic-embed-m-long', 'sources': {'hf': 'snowflake/snowflake-arctic-embed-m-long', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'Text embeddings, Unimodal (text), English, 2048 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.', 'license': 'apache-2.0', 'size_in_GB': 0.54, 'additional_files': [], 'dim': 768, 'tasks': {}}\n",
      "{'model': 'snowflake/snowflake-arctic-embed-l', 'sources': {'hf': 'snowflake/snowflake-arctic-embed-l', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.', 'license': 'apache-2.0', 'size_in_GB': 1.02, 'additional_files': [], 'dim': 1024, 'tasks': {}}\n",
      "{'model': 'jinaai/jina-clip-v1', 'sources': {'hf': 'jinaai/jina-clip-v1', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/text_model.onnx', 'description': 'Text embeddings, Multimodal (text&image), English, Prefixes for queries/documents: not necessary, 2024 year', 'license': 'apache-2.0', 'size_in_GB': 0.55, 'additional_files': [], 'dim': 768, 'tasks': {}}\n",
      "{'model': 'Qdrant/clip-ViT-B-32-text', 'sources': {'hf': 'Qdrant/clip-ViT-B-32-text', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'model.onnx', 'description': 'Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year', 'license': 'mit', 'size_in_GB': 0.25, 'additional_files': [], 'dim': 512, 'tasks': {}}\n",
      "{'model': 'sentence-transformers/all-MiniLM-L6-v2', 'sources': {'hf': 'qdrant/all-MiniLM-L6-v2-onnx', 'url': 'https://storage.googleapis.com/qdrant-fastembed/sentence-transformers-all-MiniLM-L6-v2.tar.gz', '_deprecated_tar_struct': True}, 'model_file': 'model.onnx', 'description': 'Text embeddings, Unimodal (text), English, 256 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year.', 'license': 'apache-2.0', 'size_in_GB': 0.09, 'additional_files': [], 'dim': 384, 'tasks': {}}\n",
      "{'model': 'jinaai/jina-embeddings-v2-base-en', 'sources': {'hf': 'xenova/jina-embeddings-v2-base-en', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.', 'license': 'apache-2.0', 'size_in_GB': 0.52, 'additional_files': [], 'dim': 768, 'tasks': {}}\n",
      "{'model': 'jinaai/jina-embeddings-v2-small-en', 'sources': {'hf': 'xenova/jina-embeddings-v2-small-en', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.', 'license': 'apache-2.0', 'size_in_GB': 0.12, 'additional_files': [], 'dim': 512, 'tasks': {}}\n",
      "{'model': 'jinaai/jina-embeddings-v2-base-de', 'sources': {'hf': 'jinaai/jina-embeddings-v2-base-de', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model_fp16.onnx', 'description': 'Text embeddings, Unimodal (text), Multilingual (German, English), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.', 'license': 'apache-2.0', 'size_in_GB': 0.32, 'additional_files': [], 'dim': 768, 'tasks': {}}\n",
      "{'model': 'jinaai/jina-embeddings-v2-base-code', 'sources': {'hf': 'jinaai/jina-embeddings-v2-base-code', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'Text embeddings, Unimodal (text), Multilingual (English, 30 programming languages), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.', 'license': 'apache-2.0', 'size_in_GB': 0.64, 'additional_files': [], 'dim': 768, 'tasks': {}}\n",
      "{'model': 'jinaai/jina-embeddings-v2-base-zh', 'sources': {'hf': 'jinaai/jina-embeddings-v2-base-zh', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'Text embeddings, Unimodal (text), supports mixed Chinese-English input text, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.', 'license': 'apache-2.0', 'size_in_GB': 0.64, 'additional_files': [], 'dim': 768, 'tasks': {}}\n",
      "{'model': 'jinaai/jina-embeddings-v2-base-es', 'sources': {'hf': 'jinaai/jina-embeddings-v2-base-es', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'Text embeddings, Unimodal (text), supports mixed Spanish-English input text, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.', 'license': 'apache-2.0', 'size_in_GB': 0.64, 'additional_files': [], 'dim': 768, 'tasks': {}}\n",
      "{'model': 'thenlper/gte-base', 'sources': {'hf': 'thenlper/gte-base', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'General text embeddings, Unimodal (text), supports English only input text, 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.', 'license': 'mit', 'size_in_GB': 0.44, 'additional_files': [], 'dim': 768, 'tasks': {}}\n",
      "{'model': 'thenlper/gte-large', 'sources': {'hf': 'qdrant/gte-large-onnx', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'model.onnx', 'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.', 'license': 'mit', 'size_in_GB': 1.2, 'additional_files': [], 'dim': 1024, 'tasks': {}}\n",
      "{'model': 'nomic-ai/nomic-embed-text-v1.5', 'sources': {'hf': 'nomic-ai/nomic-embed-text-v1.5', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.', 'license': 'apache-2.0', 'size_in_GB': 0.52, 'additional_files': [], 'dim': 768, 'tasks': {}}\n",
      "{'model': 'nomic-ai/nomic-embed-text-v1.5-Q', 'sources': {'hf': 'nomic-ai/nomic-embed-text-v1.5', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model_quantized.onnx', 'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.', 'license': 'apache-2.0', 'size_in_GB': 0.13, 'additional_files': [], 'dim': 768, 'tasks': {}}\n",
      "{'model': 'nomic-ai/nomic-embed-text-v1', 'sources': {'hf': 'nomic-ai/nomic-embed-text-v1', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.', 'license': 'apache-2.0', 'size_in_GB': 0.52, 'additional_files': [], 'dim': 768, 'tasks': {}}\n",
      "{'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2', 'sources': {'hf': 'qdrant/paraphrase-multilingual-MiniLM-L12-v2-onnx-Q', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'model_optimized.onnx', 'description': 'Text embeddings, Unimodal (text), Multilingual (~50 languages), 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2019 year.', 'license': 'apache-2.0', 'size_in_GB': 0.22, 'additional_files': [], 'dim': 384, 'tasks': {}}\n",
      "{'model': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2', 'sources': {'hf': 'xenova/paraphrase-multilingual-mpnet-base-v2', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'Text embeddings, Unimodal (text), Multilingual (~50 languages), 384 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year.', 'license': 'apache-2.0', 'size_in_GB': 1.0, 'additional_files': [], 'dim': 768, 'tasks': {}}\n",
      "{'model': 'intfloat/multilingual-e5-large', 'sources': {'hf': 'qdrant/multilingual-e5-large-onnx', 'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-multilingual-e5-large.tar.gz', '_deprecated_tar_struct': True}, 'model_file': 'model.onnx', 'description': 'Text embeddings, Unimodal (text), Multilingual (~100 languages), 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.', 'license': 'mit', 'size_in_GB': 2.24, 'additional_files': ['model.onnx_data'], 'dim': 1024, 'tasks': {}}\n",
      "{'model': 'jinaai/jina-embeddings-v3', 'sources': {'hf': 'jinaai/jina-embeddings-v3', 'url': None, '_deprecated_tar_struct': False}, 'model_file': 'onnx/model.onnx', 'description': 'Multi-task unimodal (text) embedding model, multi-lingual (~100), 1024 tokens truncation, and 8192 sequence length. Prefixes for queries/documents: not necessary, 2024 year.', 'license': 'cc-by-nc-4.0', 'size_in_GB': 2.29, 'additional_files': ['onnx/model.onnx_data'], 'dim': 1024, 'tasks': {'retrieval.query': 0, 'retrieval.passage': 1, 'separation': 2, 'classification': 3, 'text-matching': 4}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\Mikita_Tryzno\\Downloads\\llm-zoomcamp-1\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Mikita_Tryzno\\AppData\\Local\\Temp\\fastembed_cache\\models--Qdrant--bge-small-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 5 files:  80%|████████  | 4/5 [03:50<00:57, 57.59s/it] \n",
      "\u001b[32m2025-06-17 15:16:28.300\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mfastembed.common.model_management\u001b[0m:\u001b[36mdownload_model\u001b[0m:\u001b[36m430\u001b[0m - \u001b[31m\u001b[1mCould not download model from HuggingFace: [WinError 1314] A required privilege is not held by the client: '..\\\\..\\\\blobs\\\\37fca74771bc76a8e01178ce3a6055a0995f8093' -> 'C:\\\\Users\\\\MIKITA~1\\\\AppData\\\\Local\\\\Temp\\\\fastembed_cache\\\\models--Qdrant--bge-small-en\\\\snapshots\\\\8791246cc2a79c7949a4dc0d4a018cbd7d024879\\\\tokenizer_config.json' Falling back to other sources.\u001b[0m\n",
      "100%|██████████| 77.7M/77.7M [00:51<00:00, 1.49MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of BAAI/bge-small-en: 384\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "\n",
    "# List available models\n",
    "available_models = TextEmbedding.list_supported_models()\n",
    "print(\"Available models:\")\n",
    "for model in available_models:\n",
    "    print(model)\n",
    "\n",
    "# Check dimensions of a smaller model\n",
    "small_model = TextEmbedding(model_name=\"BAAI/bge-small-en\")\n",
    "test_embedding = list(small_model.embed([\"test\"]))[0]\n",
    "print(f\"Dimension of BAAI/bge-small-en: {test_embedding.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "306aa025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ML Zoomcamp documents: 375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection ml_zoomcamp_faq\n",
      "Uploaded batch 1/4\n",
      "Uploaded batch 2/4\n",
      "Uploaded batch 3/4\n",
      "Uploaded batch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikita_Tryzno\\AppData\\Local\\Temp\\ipykernel_8116\\2568029523.py:75: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top result score: 0.8703172\n",
      "Question: The course has already started. Can I still join it?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "\n",
    "# Download documents\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "# Filter for ML Zoomcamp documents\n",
    "documents = []\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "print(f\"Number of ML Zoomcamp documents: {len(documents)}\")\n",
    "\n",
    "# Initialize the small embedding model\n",
    "small_model = TextEmbedding(model_name=\"BAAI/bge-small-en\")\n",
    "\n",
    "# Connect to Qdrant\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "# Create a collection\n",
    "collection_name = \"ml_zoomcamp_faq\"\n",
    "vector_size = list(small_model.embed([\"test\"]))[0].shape[0]  # Should be 384\n",
    "\n",
    "# Create collection if it doesn't exist\n",
    "try:\n",
    "    client.get_collection(collection_name)\n",
    "    print(f\"Collection {collection_name} already exists\")\n",
    "except:\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE),\n",
    "    )\n",
    "    print(f\"Created collection {collection_name}\")\n",
    "\n",
    "# Prepare documents for indexing\n",
    "points = []\n",
    "for i, doc in enumerate(documents):\n",
    "    # Combine question and text\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    \n",
    "    # Embed the text\n",
    "    embedding = list(small_model.embed([text]))[0]\n",
    "    \n",
    "    # Create a point\n",
    "    point = PointStruct(\n",
    "        id=i,\n",
    "        vector=embedding.tolist(),\n",
    "        payload=doc\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "# Upload points in batches\n",
    "batch_size = 100\n",
    "for i in range(0, len(points), batch_size):\n",
    "    batch = points[i:i+batch_size]\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=batch\n",
    "    )\n",
    "    print(f\"Uploaded batch {i//batch_size + 1}/{(len(points)-1)//batch_size + 1}\")\n",
    "\n",
    "# Query the collection\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "query_embedding = list(small_model.embed([query]))[0]\n",
    "\n",
    "search_results = client.search(\n",
    "    collection_name=collection_name,\n",
    "    query_vector=query_embedding.tolist(),\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "# Print the top result and its score\n",
    "print(f\"Top result score: {search_results[0].score}\")\n",
    "print(f\"Question: {search_results[0].payload['question']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
